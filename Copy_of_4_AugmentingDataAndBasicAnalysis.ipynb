{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copy of  4-AugmentingDataAndBasicAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivia-maras/olivia-maras/blob/main/Copy_of_4_AugmentingDataAndBasicAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDSFgLZpxPFw"
      },
      "source": [
        "### Augmenting Data in Python with Pandas\n",
        "\n",
        "One of the key features of the pandas library is that it allows us streamline in-memory manipulation of data, which can be especially useful when we want to augment our data set with information from another source.\n",
        "\n",
        "For example, while our current source data on vaccinations contains many useful elements, we might want to add information about employment, or income. Pandas lets us join data sets based on one or more columns, using different styles of joins. It also adds flag columns each time (if we choose), so that we can keep track of what has and has not been matched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F1T2-P6xPFy"
      },
      "source": [
        "# first, import the pandas library, giving it a nickname of \"pd\" for short\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrpvMXe2xQIk"
      },
      "source": [
        "# THIS CODE REQUIRED FOR GOOGLE COLAB\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "# Documentation found here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-OpFzKcxV8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128396f6-1ed2-4577-ec90-ae65d42b08a0"
      },
      "source": [
        "# THIS CODE REQUIRED FOR GOOGLE COLAB\n",
        "# Link to data file stored in Drive: https://drive.google.com/file/d/10P11wZOuwlCN9krxokxmeryOK3mnMZby/view?usp=sharing\n",
        "file_id = '10P11wZOuwlCN9krxokxmeryOK3mnMZby' # notice where this string comes from in link above\n",
        "\n",
        "imported_file = drive.CreateFile({'id': file_id}) # creating an accessible copy of the shared data file\n",
        "print(imported_file['title'])  # it should print the title of desired file\n",
        "imported_file.GetContentFile(imported_file['title']) # refer to it in this notebook by the same name as it has in Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "owid-covid-data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJBH804axPFz"
      },
      "source": [
        "# our data is stored as a csv, so we'll use the `read_csv()` method.\n",
        "# similar methods exist for other data formats, e.g. `read_excel()` or `read_stata()`\n",
        "# for a complete list of these methods, see https://pandas.pydata.org/docs/reference/io.html\n",
        "\n",
        "# we're going to take care to name our dataframe and other variables descriptively\n",
        "# this will make reading our code later much more intuitive\n",
        "vaccine_data = pd.read_csv('owid-covid-data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z9U5kdO3NUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf557fe5-3881-4cc4-f247-eed639f1fd49"
      },
      "source": [
        "# Importing some additional data to join with our current data set\n",
        "# Link to data file stored in Drive: https://drive.google.com/file/d/1JqF_AqulFQCeVn1eLCh_mHmBAI7Bw6WL/view?usp=sharing\n",
        "file_id = '1JqF_AqulFQCeVn1eLCh_mHmBAI7Bw6WL' # notice where this string comes from in link above\n",
        "\n",
        "imported_file = drive.CreateFile({'id': file_id}) # creating an accessible copy of the shared data file\n",
        "print(imported_file['title'])  # it should print the title of desired file\n",
        "imported_file.GetContentFile(imported_file['title']) # refer to it in this notebook by the same name as it has in Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wb_employment_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os7a1GowxPFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519e4e63-9d17-433b-e109-ac726d585493"
      },
      "source": [
        "# now, let's bring in some employment data and see what it contains\n",
        "\n",
        "unemp_data = pd.read_csv('wb_employment_data.csv')\n",
        "print(unemp_data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Country Name Country Code  \\\n",
            "0        Aruba          ABW   \n",
            "1  Afghanistan          AFG   \n",
            "2       Angola          AGO   \n",
            "3      Albania          ALB   \n",
            "4      Andorra          AND   \n",
            "\n",
            "                                      Indicator Name  Indicator Code  1960  \\\n",
            "0  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "1  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "2  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "3  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "4  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "\n",
            "   1961  1962  1963  1964  1965  ...   2011   2012   2013       2014  \\\n",
            "0   NaN   NaN   NaN   NaN   NaN  ...    NaN    NaN    NaN        NaN   \n",
            "1   NaN   NaN   NaN   NaN   NaN  ...  11.51  11.52  11.54  11.450000   \n",
            "2   NaN   NaN   NaN   NaN   NaN  ...   7.36   7.37   7.38   7.310000   \n",
            "3   NaN   NaN   NaN   NaN   NaN  ...  13.48  13.38  15.87  18.059999   \n",
            "4   NaN   NaN   NaN   NaN   NaN  ...    NaN    NaN    NaN        NaN   \n",
            "\n",
            "        2015   2016   2017   2018   2019   2020  \n",
            "0        NaN    NaN    NaN    NaN    NaN    NaN  \n",
            "1  11.390000  11.31  11.18  11.06  10.98  11.73  \n",
            "2   7.260000   7.20   7.10   7.00   6.93   7.70  \n",
            "3  17.190001  15.42  13.62  12.30  11.47  11.70  \n",
            "4        NaN    NaN    NaN    NaN    NaN    NaN  \n",
            "\n",
            "[5 rows x 65 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzdn8PjoxPF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8349f941-a0da-47bf-d558-8776c1050f58"
      },
      "source": [
        "# and let's remind ourselves of the columns in our vaccine_data\n",
        "print(vaccine_data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iso_code continent     location        date  total_cases  new_cases  \\\n",
            "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
            "1      AFG      Asia  Afghanistan  2020-02-25          5.0        0.0   \n",
            "2      AFG      Asia  Afghanistan  2020-02-26          5.0        0.0   \n",
            "3      AFG      Asia  Afghanistan  2020-02-27          5.0        0.0   \n",
            "4      AFG      Asia  Afghanistan  2020-02-28          5.0        0.0   \n",
            "\n",
            "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
            "0                 NaN           NaN         NaN                  NaN  ...   \n",
            "1                 NaN           NaN         NaN                  NaN  ...   \n",
            "2                 NaN           NaN         NaN                  NaN  ...   \n",
            "3                 NaN           NaN         NaN                  NaN  ...   \n",
            "4                 NaN           NaN         NaN                  NaN  ...   \n",
            "\n",
            "   female_smokers  male_smokers  handwashing_facilities  \\\n",
            "0             NaN           NaN                  37.746   \n",
            "1             NaN           NaN                  37.746   \n",
            "2             NaN           NaN                  37.746   \n",
            "3             NaN           NaN                  37.746   \n",
            "4             NaN           NaN                  37.746   \n",
            "\n",
            "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
            "0                         0.5            64.83                    0.511   \n",
            "1                         0.5            64.83                    0.511   \n",
            "2                         0.5            64.83                    0.511   \n",
            "3                         0.5            64.83                    0.511   \n",
            "4                         0.5            64.83                    0.511   \n",
            "\n",
            "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
            "0                                   NaN                          NaN   \n",
            "1                                   NaN                          NaN   \n",
            "2                                   NaN                          NaN   \n",
            "3                                   NaN                          NaN   \n",
            "4                                   NaN                          NaN   \n",
            "\n",
            "   excess_mortality  excess_mortality_cumulative_per_million  \n",
            "0               NaN                                      NaN  \n",
            "1               NaN                                      NaN  \n",
            "2               NaN                                      NaN  \n",
            "3               NaN                                      NaN  \n",
            "4               NaN                                      NaN  \n",
            "\n",
            "[5 rows x 67 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZkJMZaTxPF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933c1fcc-b257-42e7-f5b9-7021760b1068"
      },
      "source": [
        "# since unemployment is a \"lagging\" indicator, we're probably not as interested in the unemployment rate in \n",
        "# 2020 as the unemployment rate in 2019: if unemployment was high then, it may be a better predictor of a \n",
        "# country's economic state in 2020\n",
        "\n",
        "# first, let's get *just* the unemployment rates for 2019\n",
        "\n",
        "unemp_2019 = unemp_data.loc[:,['Country Code','2019']]\n",
        "print(unemp_2019)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Country Code       2019\n",
            "0            ABW        NaN\n",
            "1            AFG  10.980000\n",
            "2            AGO   6.930000\n",
            "3            ALB  11.470000\n",
            "4            AND        NaN\n",
            "..           ...        ...\n",
            "259          XKX        NaN\n",
            "260          YEM  12.900000\n",
            "261          ZAF  28.469999\n",
            "262          ZMB  11.910000\n",
            "263          ZWE   5.020000\n",
            "\n",
            "[264 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdO2kvYExPF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302a4fde-50c0-43d1-f984-cd152ae82227"
      },
      "source": [
        "# now, let's merge the unemployment data with our vaccine data\n",
        "\n",
        "new_data = vaccine_data.merge(unemp_2019, how='left', left_on='iso_code', right_on='Country Code')\n",
        "print(new_data.head().transpose())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0            1  \\\n",
            "iso_code                                         AFG          AFG   \n",
            "continent                                       Asia         Asia   \n",
            "location                                 Afghanistan  Afghanistan   \n",
            "date                                      2020-02-24   2020-02-25   \n",
            "total_cases                                      5.0          5.0   \n",
            "...                                              ...          ...   \n",
            "excess_mortality_cumulative                      NaN          NaN   \n",
            "excess_mortality                                 NaN          NaN   \n",
            "excess_mortality_cumulative_per_million          NaN          NaN   \n",
            "Country Code                                     AFG          AFG   \n",
            "2019                                           10.98        10.98   \n",
            "\n",
            "                                                   2            3            4  \n",
            "iso_code                                         AFG          AFG          AFG  \n",
            "continent                                       Asia         Asia         Asia  \n",
            "location                                 Afghanistan  Afghanistan  Afghanistan  \n",
            "date                                      2020-02-26   2020-02-27   2020-02-28  \n",
            "total_cases                                      5.0          5.0          5.0  \n",
            "...                                              ...          ...          ...  \n",
            "excess_mortality_cumulative                      NaN          NaN          NaN  \n",
            "excess_mortality                                 NaN          NaN          NaN  \n",
            "excess_mortality_cumulative_per_million          NaN          NaN          NaN  \n",
            "Country Code                                     AFG          AFG          AFG  \n",
            "2019                                           10.98        10.98        10.98  \n",
            "\n",
            "[69 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6VDAjg7xPF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db717cfa-8973-4f7c-98f4-503f09c4d259"
      },
      "source": [
        "# of course, now we have essentially a duplicate column, so let's get rid of that\n",
        "# note that in pandas, if there is an \"axis\" option, 0=rows and 1=columns; 0 is usually the default\n",
        "# there is also the more intuitive option: new_data.drop(columns=['Country Code'])\n",
        "\n",
        "trimmed_data = new_data.drop(['Country Code'], axis=1)\n",
        "print(trimmed_data.head().transpose())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0            1  \\\n",
            "iso_code                                         AFG          AFG   \n",
            "continent                                       Asia         Asia   \n",
            "location                                 Afghanistan  Afghanistan   \n",
            "date                                      2020-02-24   2020-02-25   \n",
            "total_cases                                      5.0          5.0   \n",
            "...                                              ...          ...   \n",
            "excess_mortality_cumulative_absolute             NaN          NaN   \n",
            "excess_mortality_cumulative                      NaN          NaN   \n",
            "excess_mortality                                 NaN          NaN   \n",
            "excess_mortality_cumulative_per_million          NaN          NaN   \n",
            "2019                                           10.98        10.98   \n",
            "\n",
            "                                                   2            3            4  \n",
            "iso_code                                         AFG          AFG          AFG  \n",
            "continent                                       Asia         Asia         Asia  \n",
            "location                                 Afghanistan  Afghanistan  Afghanistan  \n",
            "date                                      2020-02-26   2020-02-27   2020-02-28  \n",
            "total_cases                                      5.0          5.0          5.0  \n",
            "...                                              ...          ...          ...  \n",
            "excess_mortality_cumulative_absolute             NaN          NaN          NaN  \n",
            "excess_mortality_cumulative                      NaN          NaN          NaN  \n",
            "excess_mortality                                 NaN          NaN          NaN  \n",
            "excess_mortality_cumulative_per_million          NaN          NaN          NaN  \n",
            "2019                                           10.98        10.98        10.98  \n",
            "\n",
            "[68 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yes_1uyXxPF1"
      },
      "source": [
        "# to make our grabbing the data for a specific country easier, let's write a function!\n",
        "\n",
        "def get_country_data(df, country_code):\n",
        "  df_copy = df.copy()\n",
        "  return df_copy.loc[df_copy['iso_code']==country_code]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExvSZ40kxPF2"
      },
      "source": [
        "# and now let's just grab the data for Australia as an example\n",
        "just_AUS = get_country_data(trimmed_data, 'AUS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One calculation, three ways: Finding the mean of a column with pandas\n",
        "\n",
        "While Python, pandas and numpy all contain lots of useful \"helper\" functions for doing basic calculations, it's often worth exploring different ways of completing the same task. Sometimes one method will execute more quickly than another (which can become very important when working with a lot of data). At other times, the default operation of a helper function might not be quite what we're looking for, and so knowing another method for calculating, say, the median or different quartiles can be valuable. \n",
        "\n",
        "Here, we'll look at three different ways to find the mean: first, by \"manually\" calculating the mean by adding up all the values and dividing by the number of values, then by using numpy's built-in mean() function, then by using the one built-in to pandas. Along the way we'll confirm whether or not we get the same values in each instance, and we'll also try timing them to see which one is the fastest for us!\n",
        "\n",
        "For this exercise, we'll look at the new cases each month in Australia, and calculate the average."
      ],
      "metadata": {
        "id": "7otgkfL9NYdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if we're going to calculate the average, we first have to make sure we don't have\n",
        "# any \"NaN\" values; let's drop them\n",
        "\n",
        "# if we don't include the \"inplace\" parameter, our underlyiing DataFrame won't be changed\n",
        "just_AUS.dropna(subset=['new_cases'], inplace=True)"
      ],
      "metadata": {
        "id": "FvatjZteYVaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uh-oh. What happened?\n",
        "# well, when we wrote our `get_country_data` function, we just used square brackets, \n",
        "# rather that the `.loc` method. As a result, the `just_AUS` DataFrame is only a \"view\"\n",
        "# of our larger DataFrame, rather than a true copy. Let's fix it."
      ],
      "metadata": {
        "id": "N4Vz-DIZYoYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1T0J9zvxPF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdd02b5-352a-4b25-f239-5905c93df049"
      },
      "source": [
        "# if we want to do this \"manually,\" we'll first need to pull out the parameter of interest as its own list\n",
        "# fortunately, this is quite simple thanks to the `tolist()` method\n",
        "\n",
        "new_cases_list = just_AUS['new_cases'].tolist()\n",
        "\n",
        "all_cases = 0\n",
        "\n",
        "for case_count in new_cases_list:\n",
        "    all_cases += case_count\n",
        "\n",
        "monthly_avg = all_cases/len(new_cases_list)\n",
        "\n",
        "print(monthly_avg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9701.090100111234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FXQIp0bxPF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2749b979-ef6f-473a-b6fe-ff90b7c61c82"
      },
      "source": [
        "# we can also calculate the mean on the list using numpy functions\n",
        "\n",
        "monthly_avg_np = np.mean(new_cases_list)\n",
        "\n",
        "print(monthly_avg_np)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9701.090100111234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgjZwpYnxPF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298c5b7f-400c-4416-d74e-32676ae011c7"
      },
      "source": [
        "# or we can use the pandas function on the column of our new DataFrame\n",
        "\n",
        "monthly_avg_pd = just_AUS['new_cases'].mean()\n",
        "\n",
        "print(monthly_avg_pd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9701.090100111234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's compare how long each method takes, using the `timeit` \"magic\" command\n",
        "\n",
        "def manual_avg(data_list):\n",
        "  all_cases = 0\n",
        "\n",
        "  for case_count in data_list:\n",
        "      all_cases += case_count\n",
        "\n",
        "  monthly_avg = all_cases/len(data_list)\n",
        "\n",
        "%timeit manual_avg(new_cases_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttg6NHafTDXq",
        "outputId": "40ee6139-5095-4b36-814a-59fa860e746c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 loops, best of 5: 37.4 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit np.mean(new_cases_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJJKXptTT0yE",
        "outputId": "32eca9f0-bb30-4577-8cd3-d7ea871e0e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 loops, best of 5: 95.2 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit just_AUS['new_cases'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGkYDeksT5Qc",
        "outputId": "dc720d61-943f-44cd-ebe1-d085e1c108de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 7.14 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 5: 67.8 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We won't dig into all the reasons for these differences right now, but just know that it's something you may want to check if you have very large calculations to perform!"
      ],
      "metadata": {
        "id": "suYMLrZxaWxM"
      }
    }
  ]
}