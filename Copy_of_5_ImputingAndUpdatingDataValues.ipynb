{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copy of 5-ImputingAndUpdatingDataValues.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olivia-maras/olivia-maras/blob/main/Copy_of_5_ImputingAndUpdatingDataValues.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my7_y_RbugJ1"
      },
      "source": [
        "### Imputing and Updating Data Values in Pandas\n",
        "\n",
        "As we just saw, sometimes it can be tricky to tell just when we've made a change to an underlying data set, and when we're working with a view or a copy. \n",
        "\n",
        "While it may seem silly (why not just copy everything?), when you're working with very large data sets, there are a lot of efficiencies to be gained by *not* automatically copying all your data every time you decide you want to look at a different subset of it. As a result, however, it can be easy to run into problems where you can't quite seem to do what you want.\n",
        "\n",
        "That's because, for the purposes of data coding or analysis, we often want to be able to transform our data by recoding or recasting values, creating new data columns etc. \n",
        "\n",
        "In general, the safest way to proceed is to either:\n",
        "\n",
        "1. Perform any true data transformation on your entire data set, or\n",
        "2. Explicitly create a copy of a DataFrame before trying to update any values\n",
        "\n",
        "\n",
        "Bear in mind that the second method, in particular, can start to become memory-intensive. If you really need to \"break off\" big chunks of your data, consider downloading a separate file and focusing that work in a dedicated notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odW9AyB6ugJ2"
      },
      "source": [
        "# first, import the pandas library, giving it a nickname of \"pd\" for short\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w10yxOSSuhgN"
      },
      "source": [
        "# THIS CODE REQUIRED FOR GOOGLE COLAB\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "# Documentation found here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpJVx9RaumqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d651eb4e-cdf3-4d55-ac58-5543341b4cd1"
      },
      "source": [
        "# THIS CODE REQUIRED FOR GOOGLE COLAB\n",
        "# Link to data file stored in Drive: https://drive.google.com/file/d/10P11wZOuwlCN9krxokxmeryOK3mnMZby/view?usp=sharing\n",
        "file_id = '10P11wZOuwlCN9krxokxmeryOK3mnMZby' # notice where this string comes from in link above\n",
        "\n",
        "imported_file = drive.CreateFile({'id': file_id}) # creating an accessible copy of the shared data file\n",
        "print(imported_file['title'])  # it should print the title of desired file\n",
        "imported_file.GetContentFile(imported_file['title']) # refer to it in this notebook by the same name as it has in Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "owid-covid-data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbRT29wzugJ3"
      },
      "source": [
        "# our data is stored as a csv, so we'll use the `read_csv()` method.\n",
        "# similar methods exist for other data formats, e.g. `read_excel()` or `read_stata()`\n",
        "# for a complete list of these methods, see https://pandas.pydata.org/docs/reference/io.html\n",
        "\n",
        "# we're going to take care to name our dataframe and other variables descriptively\n",
        "# this will make reading our code later much more intuitive\n",
        "vaccine_data = pd.read_csv('owid-covid-data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unemployment data\n",
        "# Link to data file stored in Drive: https://drive.google.com/file/d/1JqF_AqulFQCeVn1eLCh_mHmBAI7Bw6WL/view?usp=sharing\n",
        "file_id = '1JqF_AqulFQCeVn1eLCh_mHmBAI7Bw6WL' # notice where this string comes from in link above\n",
        "\n",
        "imported_file = drive.CreateFile({'id': file_id}) # creating an accessible copy of the shared data file\n",
        "print(imported_file['title'])  # it should print the title of desired file\n",
        "imported_file.GetContentFile(imported_file['title']) # refer to it in this notebook by the same name as it has in Drive"
      ],
      "metadata": {
        "id": "wXSLeegmftv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f37e565-dcbb-4f1c-ed8b-2eda5eb63e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wb_employment_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QY1TQRWugJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b59507a-1d1b-45b3-f0bc-abf2a60425d7"
      },
      "source": [
        "# now, let's bring in some employment data and see what it contains\n",
        "\n",
        "unemp_data = pd.read_csv('wb_employment_data.csv')\n",
        "print(unemp_data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Country Name Country Code  \\\n",
            "0        Aruba          ABW   \n",
            "1  Afghanistan          AFG   \n",
            "2       Angola          AGO   \n",
            "3      Albania          ALB   \n",
            "4      Andorra          AND   \n",
            "\n",
            "                                      Indicator Name  Indicator Code  1960  \\\n",
            "0  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "1  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "2  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "3  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "4  Unemployment, total (% of total labor force) (...  SL.UEM.TOTL.ZS   NaN   \n",
            "\n",
            "   1961  1962  1963  1964  1965  ...   2011   2012   2013       2014  \\\n",
            "0   NaN   NaN   NaN   NaN   NaN  ...    NaN    NaN    NaN        NaN   \n",
            "1   NaN   NaN   NaN   NaN   NaN  ...  11.51  11.52  11.54  11.450000   \n",
            "2   NaN   NaN   NaN   NaN   NaN  ...   7.36   7.37   7.38   7.310000   \n",
            "3   NaN   NaN   NaN   NaN   NaN  ...  13.48  13.38  15.87  18.059999   \n",
            "4   NaN   NaN   NaN   NaN   NaN  ...    NaN    NaN    NaN        NaN   \n",
            "\n",
            "        2015   2016   2017   2018   2019   2020  \n",
            "0        NaN    NaN    NaN    NaN    NaN    NaN  \n",
            "1  11.390000  11.31  11.18  11.06  10.98  11.73  \n",
            "2   7.260000   7.20   7.10   7.00   6.93   7.70  \n",
            "3  17.190001  15.42  13.62  12.30  11.47  11.70  \n",
            "4        NaN    NaN    NaN    NaN    NaN    NaN  \n",
            "\n",
            "[5 rows x 65 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmgxQVcgugJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8ae0ac-248a-4dca-a748-650219281947"
      },
      "source": [
        "# and let's remind ourselves of the columns in our vaccine_data\n",
        "print(vaccine_data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iso_code continent     location        date  total_cases  new_cases  \\\n",
            "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
            "1      AFG      Asia  Afghanistan  2020-02-25          5.0        0.0   \n",
            "2      AFG      Asia  Afghanistan  2020-02-26          5.0        0.0   \n",
            "3      AFG      Asia  Afghanistan  2020-02-27          5.0        0.0   \n",
            "4      AFG      Asia  Afghanistan  2020-02-28          5.0        0.0   \n",
            "\n",
            "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
            "0                 NaN           NaN         NaN                  NaN  ...   \n",
            "1                 NaN           NaN         NaN                  NaN  ...   \n",
            "2                 NaN           NaN         NaN                  NaN  ...   \n",
            "3                 NaN           NaN         NaN                  NaN  ...   \n",
            "4                 NaN           NaN         NaN                  NaN  ...   \n",
            "\n",
            "   female_smokers  male_smokers  handwashing_facilities  \\\n",
            "0             NaN           NaN                  37.746   \n",
            "1             NaN           NaN                  37.746   \n",
            "2             NaN           NaN                  37.746   \n",
            "3             NaN           NaN                  37.746   \n",
            "4             NaN           NaN                  37.746   \n",
            "\n",
            "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
            "0                         0.5            64.83                    0.511   \n",
            "1                         0.5            64.83                    0.511   \n",
            "2                         0.5            64.83                    0.511   \n",
            "3                         0.5            64.83                    0.511   \n",
            "4                         0.5            64.83                    0.511   \n",
            "\n",
            "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
            "0                                   NaN                          NaN   \n",
            "1                                   NaN                          NaN   \n",
            "2                                   NaN                          NaN   \n",
            "3                                   NaN                          NaN   \n",
            "4                                   NaN                          NaN   \n",
            "\n",
            "   excess_mortality  excess_mortality_cumulative_per_million  \n",
            "0               NaN                                      NaN  \n",
            "1               NaN                                      NaN  \n",
            "2               NaN                                      NaN  \n",
            "3               NaN                                      NaN  \n",
            "4               NaN                                      NaN  \n",
            "\n",
            "[5 rows x 67 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytrcsTY2ugJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6913213-fbec-4fc9-b6ea-365b7957c310"
      },
      "source": [
        "# since unemployment is a \"lagging\" indicator, we're probably not as interested in the unemployment rate in \n",
        "# 2020 as the unemployment rate in 2019: if unemployment was high then, it may be a better predictor of a \n",
        "# country's economic state in 2020\n",
        "\n",
        "# first, let's get *just* the unemployment rates for 2019\n",
        "\n",
        "unemp_2019 = unemp_data.loc[:,['Country Code','2019']]\n",
        "print(unemp_2019)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Country Code       2019\n",
            "0            ABW        NaN\n",
            "1            AFG  10.980000\n",
            "2            AGO   6.930000\n",
            "3            ALB  11.470000\n",
            "4            AND        NaN\n",
            "..           ...        ...\n",
            "259          XKX        NaN\n",
            "260          YEM  12.900000\n",
            "261          ZAF  28.469999\n",
            "262          ZMB  11.910000\n",
            "263          ZWE   5.020000\n",
            "\n",
            "[264 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXXh_2V1ugJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32d092b-daee-4b8f-a55f-95384a0fe8b9"
      },
      "source": [
        "# now, let's merge the unemployment data with our vaccine data\n",
        "\n",
        "new_data = vaccine_data.merge(unemp_2019, how='left', left_on='iso_code', right_on='Country Code')\n",
        "print(new_data.head().transpose())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0            1  \\\n",
            "iso_code                                         AFG          AFG   \n",
            "continent                                       Asia         Asia   \n",
            "location                                 Afghanistan  Afghanistan   \n",
            "date                                      2020-02-24   2020-02-25   \n",
            "total_cases                                      5.0          5.0   \n",
            "...                                              ...          ...   \n",
            "excess_mortality_cumulative                      NaN          NaN   \n",
            "excess_mortality                                 NaN          NaN   \n",
            "excess_mortality_cumulative_per_million          NaN          NaN   \n",
            "Country Code                                     AFG          AFG   \n",
            "2019                                           10.98        10.98   \n",
            "\n",
            "                                                   2            3            4  \n",
            "iso_code                                         AFG          AFG          AFG  \n",
            "continent                                       Asia         Asia         Asia  \n",
            "location                                 Afghanistan  Afghanistan  Afghanistan  \n",
            "date                                      2020-02-26   2020-02-27   2020-02-28  \n",
            "total_cases                                      5.0          5.0          5.0  \n",
            "...                                              ...          ...          ...  \n",
            "excess_mortality_cumulative                      NaN          NaN          NaN  \n",
            "excess_mortality                                 NaN          NaN          NaN  \n",
            "excess_mortality_cumulative_per_million          NaN          NaN          NaN  \n",
            "Country Code                                     AFG          AFG          AFG  \n",
            "2019                                           10.98        10.98        10.98  \n",
            "\n",
            "[69 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE1gDpqQugJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a97e437-e395-4bb2-b6c2-25e3c1b724e8"
      },
      "source": [
        "# of course, now we have essentially a duplicate column, so let's get rid of that\n",
        "# note that in pandas, if there is an \"axis\" option, 0=rows and 1=columns; 0 is usually the default\n",
        "# there is also the more intuitive option: new_data.drop(columns=['Country Code'])\n",
        "\n",
        "trimmed_data = new_data.drop(['Country Code'], axis=1)\n",
        "print(trimmed_data.head().transpose())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   0            1  \\\n",
            "iso_code                                         AFG          AFG   \n",
            "continent                                       Asia         Asia   \n",
            "location                                 Afghanistan  Afghanistan   \n",
            "date                                      2020-02-24   2020-02-25   \n",
            "total_cases                                      5.0          5.0   \n",
            "...                                              ...          ...   \n",
            "excess_mortality_cumulative_absolute             NaN          NaN   \n",
            "excess_mortality_cumulative                      NaN          NaN   \n",
            "excess_mortality                                 NaN          NaN   \n",
            "excess_mortality_cumulative_per_million          NaN          NaN   \n",
            "2019                                           10.98        10.98   \n",
            "\n",
            "                                                   2            3            4  \n",
            "iso_code                                         AFG          AFG          AFG  \n",
            "continent                                       Asia         Asia         Asia  \n",
            "location                                 Afghanistan  Afghanistan  Afghanistan  \n",
            "date                                      2020-02-26   2020-02-27   2020-02-28  \n",
            "total_cases                                      5.0          5.0          5.0  \n",
            "...                                              ...          ...          ...  \n",
            "excess_mortality_cumulative_absolute             NaN          NaN          NaN  \n",
            "excess_mortality_cumulative                      NaN          NaN          NaN  \n",
            "excess_mortality                                 NaN          NaN          NaN  \n",
            "excess_mortality_cumulative_per_million          NaN          NaN          NaN  \n",
            "2019                                           10.98        10.98        10.98  \n",
            "\n",
            "[68 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuA6G6UfugJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73f0387-c3fb-4598-9f36-416c2912f323"
      },
      "source": [
        "# let's say we want to treat \"total_cases_per_million\" of less than 1% as NaN\n",
        "\n",
        "# we're going to use the '.loc' method\n",
        "#the first parameter identifies the cells to update\n",
        "#second parameter is cells to change\n",
        "# the third value is th enew value they should have\n",
        "# convert values np.nan\n",
        "\n",
        "trimmed_data.loc[trimmed_data['total_cases_per_million'] <= 10000, 'total_cases_per_million'] = np.nan\n",
        "\n",
        "AUS_filter = trimmed_data['iso_code'] =='AUS'\n",
        "\n",
        "just_AUS = trimmed_data[AUS_filter]\n",
        "\n",
        "print(just_AUS[['date', 'total_cases_per_million']])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             date  total_cases_per_million\n",
            "10480  2020-01-26                      NaN\n",
            "10481  2020-01-27                      NaN\n",
            "10482  2020-01-28                      NaN\n",
            "10483  2020-01-29                      NaN\n",
            "10484  2020-01-30                      NaN\n",
            "...           ...                      ...\n",
            "11376  2022-07-10               328568.256\n",
            "11377  2022-07-11               330293.646\n",
            "11378  2022-07-12               332007.116\n",
            "11379  2022-07-13               333823.976\n",
            "11380  2022-07-14               335319.631\n",
            "\n",
            "[901 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More ways to create new DataFrames\n",
        "\n",
        "Sometimes the idea of \"cuttng down\" a large DataFrame is tedious, especially if there are many columns and you don't want to mess with lots of sub-selecting. Recall that you can always convert a DataFrame column to a list - and lists can be easily \"zipped up\" into new DataFrames!\n",
        "\n",
        "Likewise, if all you have are lists, this approach is handy for getting them into a more usable DataFrame format."
      ],
      "metadata": {
        "id": "2yYibDC3hGA6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMuM__p8ugJ9"
      },
      "source": [
        "What if I want to make a new DataFrame from just a few columns from this existing one? Rather than dropping lots of columns, I can pull out the ones I want into lists and then `zip` them up into a new DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR4o80uCugJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "05db5ff4-17a3-4955-ffcc-150cdd10ddff"
      },
      "source": [
        "from pandas._libs.tslibs.timezones import dateutil_gettz\n",
        "# pull out date, total_cases, new_cases, and new_deaths\n",
        "# to the `tolist()` function does exactly that\n",
        "\n",
        "date_list = just_AUS['date'].tolist()\n",
        "total_list = just_AUS['total_cases'].tolist()\n",
        "new_cases_list=just_AUS['new_cases'].tolist()\n",
        "new_deaths_list=just_AUS('new_deaths').tolist()\n",
        "\n",
        "# zip them up into a new DataFrame\n",
        "\n",
        "AUS_from_lists=pd.DataFrame(zip(date_list, total_list, new_cases_list, new_deaths_list), columns=['my_date', 'my_total', 'my_new_cases', 'my_new_deaths'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c9a3fcc2930e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtotal_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjust_AUS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnew_cases_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjust_AUS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_cases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnew_deaths_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjust_AUS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new_deaths'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# zip them up into a new DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsBMkSs5ugKA"
      },
      "source": [
        "### Creating new columns from existing data\n",
        "\n",
        "Sometimes we might want to create a new column based on an existing column. For example, I might want to compile a sort of \"sum\" column from two existing columns of data. pandas also makes this easy, especially through the use of `lambda` (unnamed) functions, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlcBVWFfugKB"
      },
      "source": [
        "# a `lambda` function is essentially an unnamed function that exists only within the function that \n",
        "# calls it. This is handy if you only want to do something very basic to a column, as lambda functions\n",
        "# can only contain a single expression (e.g. `row.new_cases + row.new_deaths`)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuVEPqEsugKB"
      },
      "source": [
        "# however, we can also do the same thing with a named function\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}